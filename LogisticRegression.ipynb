{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "Nothing much in this cell after \"data.npz\" was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "data = np.load('data.npz')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn Imports and Data Preprocessing\n",
    "Importing necessary SKLearn packages and preprocessing the data (Scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Model\n",
    "Just the normal Logistic Regression model and its scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Accuracy: 0.9699\n",
      "Default Precision: 0.5500\n",
      "Default Recall: 0.2558\n",
      "Default F1 Score: 0.3492\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1321\n",
      "           1       0.55      0.26      0.35        43\n",
      "\n",
      "    accuracy                           0.97      1364\n",
      "   macro avg       0.76      0.62      0.67      1364\n",
      "weighted avg       0.96      0.97      0.96      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.squeeze()\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Default Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Default Precision: {precision:.4f}\")\n",
    "print(f\"Default Recall: {recall:.4f}\")\n",
    "print(f\"Default F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "metrics['Model 1'] = [accuracy, precision, recall, f1] \n",
    "\n",
    "#coefficients = logistic_model.coef_\n",
    "#print(\"Coefficients:\", coefficients)\n",
    "\n",
    "# y_probs = logistic_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# thresholds = [0.3, 0.4, 0.5, 0.6]\n",
    "# for thresh in thresholds:\n",
    "#     y_pred_thresh = np.where(y_probs > thresh, 1, 0)\n",
    "#     print(f\"Threshold: {thresh}\")\n",
    "#     print(f\"Accuracy: {accuracy_score(y_test, y_pred_thresh):.4f}\")\n",
    "#     print(f\"Precision: {precision_score(y_test, y_pred_thresh):.4f}\")\n",
    "#     print(f\"Recall: {recall_score(y_test, y_pred_thresh):.4f}\")\n",
    "#     print(f\"F1 Score: {f1_score(y_test, y_pred_thresh):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model With Class Weight and Max Iterations (To Optimize for Recall)\n",
    "A Logistic Regression model optimized for Recall. There is a tradeoff in precision. (Lots of false positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Accuracy: 0.8710\n",
      "Default Precision: 0.1692\n",
      "Default Recall: 0.7907\n",
      "Default F1 Score: 0.2787\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93      1321\n",
      "           1       0.17      0.79      0.28        43\n",
      "\n",
      "    accuracy                           0.87      1364\n",
      "   macro avg       0.58      0.83      0.60      1364\n",
      "weighted avg       0.97      0.87      0.91      1364\n",
      "\n",
      "Final custom score on test set: 0.8108\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(class_weight='balanced', max_iter=500)\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Default Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Default Precision: {precision:.4f}\")\n",
    "print(f\"Default Recall: {recall:.4f}\")\n",
    "print(f\"Default F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "metrics['Model 2'] = [accuracy, precision, recall, f1] \n",
    "\n",
    "# y_probs = logistic_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# thresholds = [0.3, 0.4, 0.5, 0.6]\n",
    "# for thresh in thresholds:\n",
    "#     y_pred_thresh = np.where(y_probs > thresh, 1, 0)\n",
    "#     print(f\"Threshold: {thresh}\")\n",
    "#     print(f\"Accuracy: {accuracy_score(y_test, y_pred_thresh):.4f}\")\n",
    "#     print(f\"Precision: {precision_score(y_test, y_pred_thresh):.4f}\")\n",
    "#     print(f\"Recall: {recall_score(y_test, y_pred_thresh):.4f}\")\n",
    "#     print(f\"F1 Score: {f1_score(y_test, y_pred_thresh):.4f}\")\n",
    "\n",
    "def custom_score(y_true, y_pred):\n",
    "    recall_weight = 0.75\n",
    "    accuracy_weight = 0.25\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return recall * recall_weight + accuracy * accuracy_weight\n",
    "\n",
    "final_score = custom_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Final custom score on test set: {final_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "This will get the best recall score for the regularization strength (C) and the max number of iterations (max_iter) on the Logistic Regression Model below. There will be Convergence Warnings due to non-convergence.\n",
    "\n",
    "## Best Hyperparameters Based on Testing with Cross-Validation (cv=5)\n",
    "- Recall: \n",
    "    - class_weight='balanced'\n",
    "    - C=0.01\n",
    "    - max_iter=100\n",
    "- Accuracy:\n",
    "    - class_weight='None'\n",
    "    - C=0.01\n",
    "    - max_iter=100\n",
    "- F1:\n",
    "    - class_weight='None'\n",
    "    - C=10\n",
    "    - max_iter=500\n",
    "- Precision:\n",
    "    - class_weight='None'\n",
    "    - C=0.01\n",
    "    - max_iter=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 500, 1000]}\n",
    "\n",
    "# search = GridSearchCV(LogisticRegression(class_weight='balanced'), grid, scoring='recall', cv=5)\n",
    "# search.fit(X_train, y_train)\n",
    "\n",
    "# print(f\"Best parameters: {search.best_params_}\")\n",
    "# print(f\"Best recall from CV: {search.best_score_:.4f}\")\n",
    "\n",
    "# scores = ['accuracy', 'f1', 'precision']\n",
    "# for score in scores:\n",
    "#     search = GridSearchCV(LogisticRegression(), grid, scoring=score, cv=5)\n",
    "#     search.fit(X_train, y_train)\n",
    "\n",
    "#     print(f\"Best parameters: {search.best_params_}\")\n",
    "#     print(f\"Best {score} from CV: {search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Method\n",
    "This method has returned the best results so far across the board.\n",
    "\n",
    "## Best Hyperparameters for each Model\n",
    "Many calues of C, class_weight, and max_iter were tested for each model in the ensemble.\n",
    "- Recall:\n",
    "    - C=0.1\n",
    "    - class_weight='balanced'\n",
    "    - max_iter=100\n",
    "- Accuracy:\n",
    "    - C=0.1\n",
    "    - class_weight=None\n",
    "    - max_iter=100\n",
    "\n",
    "## Best Parameters in the Ensemble\n",
    "Different values of voting and weights were tried to maximize recall, precision, and accuracy. There is an inverse relationship between precision and recall because recall goes up when more positives get predicted and precision goes down because a lot of these positives are false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.9567\n",
      "Ensemble Precision: 0.3788\n",
      "Ensemble Recall: 0.5814\n",
      "Ensemble F1 Score: 0.4587\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1321\n",
      "           1       0.38      0.58      0.46        43\n",
      "\n",
      "    accuracy                           0.96      1364\n",
      "   macro avg       0.68      0.78      0.72      1364\n",
      "weighted avg       0.97      0.96      0.96      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_recall = LogisticRegression(C=0.1, class_weight='balanced', max_iter=100)\n",
    "\n",
    "model_accuracy = LogisticRegression(C=0.1, class_weight=None, max_iter=100)\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('recall_opt', model_recall),\n",
    "    ('accuracy_opt', model_accuracy)\n",
    "], voting='soft', weights=[1,1])\n",
    "\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "y_pred_ensemble = ensemble_model.predict(X_test)\n",
    "\n",
    "ensemble_accuracy = accuracy_score(y_test, y_pred_ensemble)\n",
    "ensemble_precision = precision_score(y_test, y_pred_ensemble)\n",
    "ensemble_recall = recall_score(y_test, y_pred_ensemble)\n",
    "ensemble_f1 = f1_score(y_test, y_pred_ensemble)\n",
    "\n",
    "print(f\"Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n",
    "print(f\"Ensemble Precision: {ensemble_precision:.4f}\")\n",
    "print(f\"Ensemble Recall: {ensemble_recall:.4f}\")\n",
    "print(f\"Ensemble F1 Score: {ensemble_f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_ensemble))\n",
    "\n",
    "metrics['Model 3'] = [ensemble_accuracy, ensemble_precision, ensemble_recall, ensemble_f1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = list(metrics.keys())\n",
    "\n",
    "metric_types = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "x = np.arange(len(metric_types))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "width = 0.25\n",
    "for i, model in enumerate(model_names):\n",
    "    ax.bar(x + i * width, metrics[model], width, label=model)\n",
    "\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Comparison of Logistic Regression Models')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(metric_types)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Important Features\n",
    "This will print out the most significant features (based on their weights in 100 randomly shuffled LogisticRegression models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data.npz')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = y_train.squeeze()\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "num_models = 5\n",
    "feature_per_model = 19\n",
    "total_features = X_train.shape[1]\n",
    "assert total_features == 95, \"The total number of features is not 95 as expected.\"\n",
    "\n",
    "indices = np.arange(total_features)\n",
    "\n",
    "important_features_dict = {}\n",
    "model_results = {}\n",
    "final_features = {index: {'count': 0} for index in indices}\n",
    "\n",
    "for run in range(0, 100):\n",
    "    np.random.shuffle(indices)\n",
    "    feature_groups = np.array_split(indices, num_models)\n",
    "    important_features = [] \n",
    "\n",
    "    for i, features in enumerate(feature_groups, start=1):\n",
    "        X_train_subset = X_train[:, features]\n",
    "        X_test_subset = X_test[:, features]\n",
    "\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train_subset, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test_subset)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        model_results[f'Model_{run}.{i}'] = {\n",
    "            'Features': features,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'Coefficients': model.coef_\n",
    "        }\n",
    "\n",
    "        # print(f\"Model {run}.{i} Results:\")\n",
    "        # print(f\"Features: {features}\")\n",
    "        # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        # print(f\"Precision: {precision:.4f}\")\n",
    "        # print(f\"Recall: {recall:.4f}\")\n",
    "        # print(f\"F1 Score: {f1:.4f}\")\n",
    "        # print(f\"Coefficients: {model.coef_}\\n\")\n",
    "        for x in range(len(model.coef_[0])):\n",
    "            if model.coef_[0][x] > 0.5 or model.coef_[0][x] < -0.5:\n",
    "                #print(f\"Feature index with high/low weight: {features[x]}\")\n",
    "                important_features.append(features[x])\n",
    "                final_features[features[x]]['count'] += 1\n",
    "\n",
    "    important_features_dict[f'Run_{run}'] = {'Features': important_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Different Logistic Regression Models on Different Number of Features\n",
    "feature_data['count] is basically the relevancy score a feature has in making a classification. The higher the count, the more often you will find that feature having a high weight in a logistic regression model that is being trained on a subset of the full feature set. This means that features with count equal to 100 will have a high weight in all 100 model iterations that this feature can be found in. Ultimately, this count is meaningless because the logistic regression models trained on all features have the best performance on the test set. This information will be used in our other models on this bankruptcy data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'count': 48}, 1: {'count': 29}, 2: {'count': 56}, 3: {'count': 0}, 4: {'count': 0}, 5: {'count': 79}, 6: {'count': 38}, 7: {'count': 25}, 8: {'count': 33}, 9: {'count': 17}, 10: {'count': 0}, 11: {'count': 0}, 12: {'count': 4}, 13: {'count': 8}, 14: {'count': 33}, 15: {'count': 92}, 16: {'count': 60}, 17: {'count': 59}, 18: {'count': 100}, 19: {'count': 4}, 20: {'count': 7}, 21: {'count': 48}, 22: {'count': 60}, 23: {'count': 0}, 24: {'count': 0}, 25: {'count': 0}, 26: {'count': 0}, 27: {'count': 0}, 28: {'count': 0}, 29: {'count': 0}, 30: {'count': 2}, 31: {'count': 1}, 32: {'count': 62}, 33: {'count': 0}, 34: {'count': 0}, 35: {'count': 13}, 36: {'count': 91}, 37: {'count': 91}, 38: {'count': 0}, 39: {'count': 14}, 40: {'count': 0}, 41: {'count': 47}, 42: {'count': 99}, 43: {'count': 5}, 44: {'count': 73}, 45: {'count': 8}, 46: {'count': 0}, 47: {'count': 0}, 48: {'count': 0}, 49: {'count': 33}, 50: {'count': 0}, 51: {'count': 6}, 52: {'count': 0}, 53: {'count': 35}, 54: {'count': 16}, 55: {'count': 24}, 56: {'count': 98}, 57: {'count': 0}, 58: {'count': 0}, 59: {'count': 52}, 60: {'count': 2}, 61: {'count': 0}, 62: {'count': 91}, 63: {'count': 10}, 64: {'count': 46}, 65: {'count': 12}, 66: {'count': 0}, 67: {'count': 1}, 68: {'count': 83}, 69: {'count': 4}, 70: {'count': 0}, 71: {'count': 0}, 72: {'count': 50}, 73: {'count': 0}, 74: {'count': 6}, 75: {'count': 0}, 76: {'count': 15}, 77: {'count': 11}, 78: {'count': 3}, 79: {'count': 0}, 80: {'count': 7}, 81: {'count': 3}, 82: {'count': 0}, 83: {'count': 0}, 84: {'count': 1}, 85: {'count': 47}, 86: {'count': 0}, 87: {'count': 0}, 88: {'count': 0}, 89: {'count': 4}, 90: {'count': 16}, 91: {'count': 0}, 92: {'count': 0}, 93: {'count': 0}, 94: {'count': 57}}\n",
      "Feature index 0 has a significant count of 48\n",
      "Feature index 1 has a significant count of 29\n",
      "Feature index 2 has a significant count of 56\n",
      "Feature index 3 has a significant count of 0\n",
      "Feature index 4 has a significant count of 0\n",
      "Feature index 5 has a significant count of 79\n",
      "Feature index 6 has a significant count of 38\n",
      "Feature index 7 has a significant count of 25\n",
      "Feature index 8 has a significant count of 33\n",
      "Feature index 9 has a significant count of 17\n",
      "Feature index 10 has a significant count of 0\n",
      "Feature index 11 has a significant count of 0\n",
      "Feature index 12 has a significant count of 4\n",
      "Feature index 13 has a significant count of 8\n",
      "Feature index 14 has a significant count of 33\n",
      "Feature index 15 has a significant count of 92\n",
      "Feature index 16 has a significant count of 60\n",
      "Feature index 17 has a significant count of 59\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 19 has a significant count of 4\n",
      "Feature index 20 has a significant count of 7\n",
      "Feature index 21 has a significant count of 48\n",
      "Feature index 22 has a significant count of 60\n",
      "Feature index 23 has a significant count of 0\n",
      "Feature index 24 has a significant count of 0\n",
      "Feature index 25 has a significant count of 0\n",
      "Feature index 26 has a significant count of 0\n",
      "Feature index 27 has a significant count of 0\n",
      "Feature index 28 has a significant count of 0\n",
      "Feature index 29 has a significant count of 0\n",
      "Feature index 30 has a significant count of 2\n",
      "Feature index 31 has a significant count of 1\n",
      "Feature index 32 has a significant count of 62\n",
      "Feature index 33 has a significant count of 0\n",
      "Feature index 34 has a significant count of 0\n",
      "Feature index 35 has a significant count of 13\n",
      "Feature index 36 has a significant count of 91\n",
      "Feature index 37 has a significant count of 91\n",
      "Feature index 38 has a significant count of 0\n",
      "Feature index 39 has a significant count of 14\n",
      "Feature index 40 has a significant count of 0\n",
      "Feature index 41 has a significant count of 47\n",
      "Feature index 42 has a significant count of 99\n",
      "Feature index 43 has a significant count of 5\n",
      "Feature index 44 has a significant count of 73\n",
      "Feature index 45 has a significant count of 8\n",
      "Feature index 46 has a significant count of 0\n",
      "Feature index 47 has a significant count of 0\n",
      "Feature index 48 has a significant count of 0\n",
      "Feature index 49 has a significant count of 33\n",
      "Feature index 50 has a significant count of 0\n",
      "Feature index 51 has a significant count of 6\n",
      "Feature index 52 has a significant count of 0\n",
      "Feature index 53 has a significant count of 35\n",
      "Feature index 54 has a significant count of 16\n",
      "Feature index 55 has a significant count of 24\n",
      "Feature index 56 has a significant count of 98\n",
      "Feature index 57 has a significant count of 0\n",
      "Feature index 58 has a significant count of 0\n",
      "Feature index 59 has a significant count of 52\n",
      "Feature index 60 has a significant count of 2\n",
      "Feature index 61 has a significant count of 0\n",
      "Feature index 62 has a significant count of 91\n",
      "Feature index 63 has a significant count of 10\n",
      "Feature index 64 has a significant count of 46\n",
      "Feature index 65 has a significant count of 12\n",
      "Feature index 66 has a significant count of 0\n",
      "Feature index 67 has a significant count of 1\n",
      "Feature index 68 has a significant count of 83\n",
      "Feature index 69 has a significant count of 4\n",
      "Feature index 70 has a significant count of 0\n",
      "Feature index 71 has a significant count of 0\n",
      "Feature index 72 has a significant count of 50\n",
      "Feature index 73 has a significant count of 0\n",
      "Feature index 74 has a significant count of 6\n",
      "Feature index 75 has a significant count of 0\n",
      "Feature index 76 has a significant count of 15\n",
      "Feature index 77 has a significant count of 11\n",
      "Feature index 78 has a significant count of 3\n",
      "Feature index 79 has a significant count of 0\n",
      "Feature index 80 has a significant count of 7\n",
      "Feature index 81 has a significant count of 3\n",
      "Feature index 82 has a significant count of 0\n",
      "Feature index 83 has a significant count of 0\n",
      "Feature index 84 has a significant count of 1\n",
      "Feature index 85 has a significant count of 47\n",
      "Feature index 86 has a significant count of 0\n",
      "Feature index 87 has a significant count of 0\n",
      "Feature index 88 has a significant count of 0\n",
      "Feature index 89 has a significant count of 4\n",
      "Feature index 90 has a significant count of 16\n",
      "Feature index 91 has a significant count of 0\n",
      "Feature index 92 has a significant count of 0\n",
      "Feature index 93 has a significant count of 0\n",
      "Feature index 94 has a significant count of 57\n",
      "Results for Logistic Regression model trained on selected features with significance count of 0 or more:\n",
      "Accuracy: 0.9699\n",
      "Precision: 0.5500\n",
      "Recall: 0.2558\n",
      "F1 Score: 0.3492\n",
      "Feature index 0 has a significant count of 48\n",
      "Feature index 1 has a significant count of 29\n",
      "Feature index 2 has a significant count of 56\n",
      "Feature index 5 has a significant count of 79\n",
      "Feature index 6 has a significant count of 38\n",
      "Feature index 7 has a significant count of 25\n",
      "Feature index 8 has a significant count of 33\n",
      "Feature index 9 has a significant count of 17\n",
      "Feature index 13 has a significant count of 8\n",
      "Feature index 14 has a significant count of 33\n",
      "Feature index 15 has a significant count of 92\n",
      "Feature index 16 has a significant count of 60\n",
      "Feature index 17 has a significant count of 59\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 20 has a significant count of 7\n",
      "Feature index 21 has a significant count of 48\n",
      "Feature index 22 has a significant count of 60\n",
      "Feature index 32 has a significant count of 62\n",
      "Feature index 35 has a significant count of 13\n",
      "Feature index 36 has a significant count of 91\n",
      "Feature index 37 has a significant count of 91\n",
      "Feature index 39 has a significant count of 14\n",
      "Feature index 41 has a significant count of 47\n",
      "Feature index 42 has a significant count of 99\n",
      "Feature index 43 has a significant count of 5\n",
      "Feature index 44 has a significant count of 73\n",
      "Feature index 45 has a significant count of 8\n",
      "Feature index 49 has a significant count of 33\n",
      "Feature index 51 has a significant count of 6\n",
      "Feature index 53 has a significant count of 35\n",
      "Feature index 54 has a significant count of 16\n",
      "Feature index 55 has a significant count of 24\n",
      "Feature index 56 has a significant count of 98\n",
      "Feature index 59 has a significant count of 52\n",
      "Feature index 62 has a significant count of 91\n",
      "Feature index 63 has a significant count of 10\n",
      "Feature index 64 has a significant count of 46\n",
      "Feature index 65 has a significant count of 12\n",
      "Feature index 68 has a significant count of 83\n",
      "Feature index 72 has a significant count of 50\n",
      "Feature index 74 has a significant count of 6\n",
      "Feature index 76 has a significant count of 15\n",
      "Feature index 77 has a significant count of 11\n",
      "Feature index 80 has a significant count of 7\n",
      "Feature index 85 has a significant count of 47\n",
      "Feature index 90 has a significant count of 16\n",
      "Feature index 94 has a significant count of 57\n",
      "Results for Logistic Regression model trained on selected features with significance count of 5 or more:\n",
      "Accuracy: 0.9685\n",
      "Precision: 0.5000\n",
      "Recall: 0.2558\n",
      "F1 Score: 0.3385\n",
      "Feature index 0 has a significant count of 48\n",
      "Feature index 1 has a significant count of 29\n",
      "Feature index 2 has a significant count of 56\n",
      "Feature index 5 has a significant count of 79\n",
      "Feature index 6 has a significant count of 38\n",
      "Feature index 7 has a significant count of 25\n",
      "Feature index 8 has a significant count of 33\n",
      "Feature index 9 has a significant count of 17\n",
      "Feature index 14 has a significant count of 33\n",
      "Feature index 15 has a significant count of 92\n",
      "Feature index 16 has a significant count of 60\n",
      "Feature index 17 has a significant count of 59\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 21 has a significant count of 48\n",
      "Feature index 22 has a significant count of 60\n",
      "Feature index 32 has a significant count of 62\n",
      "Feature index 35 has a significant count of 13\n",
      "Feature index 36 has a significant count of 91\n",
      "Feature index 37 has a significant count of 91\n",
      "Feature index 39 has a significant count of 14\n",
      "Feature index 41 has a significant count of 47\n",
      "Feature index 42 has a significant count of 99\n",
      "Feature index 44 has a significant count of 73\n",
      "Feature index 49 has a significant count of 33\n",
      "Feature index 53 has a significant count of 35\n",
      "Feature index 54 has a significant count of 16\n",
      "Feature index 55 has a significant count of 24\n",
      "Feature index 56 has a significant count of 98\n",
      "Feature index 59 has a significant count of 52\n",
      "Feature index 62 has a significant count of 91\n",
      "Feature index 63 has a significant count of 10\n",
      "Feature index 64 has a significant count of 46\n",
      "Feature index 65 has a significant count of 12\n",
      "Feature index 68 has a significant count of 83\n",
      "Feature index 72 has a significant count of 50\n",
      "Feature index 76 has a significant count of 15\n",
      "Feature index 77 has a significant count of 11\n",
      "Feature index 85 has a significant count of 47\n",
      "Feature index 90 has a significant count of 16\n",
      "Feature index 94 has a significant count of 57\n",
      "Results for Logistic Regression model trained on selected features with significance count of 10 or more:\n",
      "Accuracy: 0.9670\n",
      "Precision: 0.4545\n",
      "Recall: 0.2326\n",
      "F1 Score: 0.3077\n",
      "Feature index 0 has a significant count of 48\n",
      "Feature index 1 has a significant count of 29\n",
      "Feature index 2 has a significant count of 56\n",
      "Feature index 5 has a significant count of 79\n",
      "Feature index 6 has a significant count of 38\n",
      "Feature index 7 has a significant count of 25\n",
      "Feature index 8 has a significant count of 33\n",
      "Feature index 14 has a significant count of 33\n",
      "Feature index 15 has a significant count of 92\n",
      "Feature index 16 has a significant count of 60\n",
      "Feature index 17 has a significant count of 59\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 21 has a significant count of 48\n",
      "Feature index 22 has a significant count of 60\n",
      "Feature index 32 has a significant count of 62\n",
      "Feature index 36 has a significant count of 91\n",
      "Feature index 37 has a significant count of 91\n",
      "Feature index 41 has a significant count of 47\n",
      "Feature index 42 has a significant count of 99\n",
      "Feature index 44 has a significant count of 73\n",
      "Feature index 49 has a significant count of 33\n",
      "Feature index 53 has a significant count of 35\n",
      "Feature index 55 has a significant count of 24\n",
      "Feature index 56 has a significant count of 98\n",
      "Feature index 59 has a significant count of 52\n",
      "Feature index 62 has a significant count of 91\n",
      "Feature index 64 has a significant count of 46\n",
      "Feature index 68 has a significant count of 83\n",
      "Feature index 72 has a significant count of 50\n",
      "Feature index 85 has a significant count of 47\n",
      "Feature index 94 has a significant count of 57\n",
      "Results for Logistic Regression model trained on selected features with significance count of 20 or more:\n",
      "Accuracy: 0.9677\n",
      "Precision: 0.4706\n",
      "Recall: 0.1860\n",
      "F1 Score: 0.2667\n",
      "Feature index 0 has a significant count of 48\n",
      "Feature index 2 has a significant count of 56\n",
      "Feature index 5 has a significant count of 79\n",
      "Feature index 6 has a significant count of 38\n",
      "Feature index 8 has a significant count of 33\n",
      "Feature index 14 has a significant count of 33\n",
      "Feature index 15 has a significant count of 92\n",
      "Feature index 16 has a significant count of 60\n",
      "Feature index 17 has a significant count of 59\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 21 has a significant count of 48\n",
      "Feature index 22 has a significant count of 60\n",
      "Feature index 32 has a significant count of 62\n",
      "Feature index 36 has a significant count of 91\n",
      "Feature index 37 has a significant count of 91\n",
      "Feature index 41 has a significant count of 47\n",
      "Feature index 42 has a significant count of 99\n",
      "Feature index 44 has a significant count of 73\n",
      "Feature index 49 has a significant count of 33\n",
      "Feature index 53 has a significant count of 35\n",
      "Feature index 56 has a significant count of 98\n",
      "Feature index 59 has a significant count of 52\n",
      "Feature index 62 has a significant count of 91\n",
      "Feature index 64 has a significant count of 46\n",
      "Feature index 68 has a significant count of 83\n",
      "Feature index 72 has a significant count of 50\n",
      "Feature index 85 has a significant count of 47\n",
      "Feature index 94 has a significant count of 57\n",
      "Results for Logistic Regression model trained on selected features with significance count of 30 or more:\n",
      "Accuracy: 0.9670\n",
      "Precision: 0.4444\n",
      "Recall: 0.1860\n",
      "F1 Score: 0.2623\n",
      "Feature index 0 has a significant count of 48\n",
      "Feature index 2 has a significant count of 56\n",
      "Feature index 5 has a significant count of 79\n",
      "Feature index 15 has a significant count of 92\n",
      "Feature index 16 has a significant count of 60\n",
      "Feature index 17 has a significant count of 59\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 21 has a significant count of 48\n",
      "Feature index 22 has a significant count of 60\n",
      "Feature index 32 has a significant count of 62\n",
      "Feature index 36 has a significant count of 91\n",
      "Feature index 37 has a significant count of 91\n",
      "Feature index 41 has a significant count of 47\n",
      "Feature index 42 has a significant count of 99\n",
      "Feature index 44 has a significant count of 73\n",
      "Feature index 56 has a significant count of 98\n",
      "Feature index 59 has a significant count of 52\n",
      "Feature index 62 has a significant count of 91\n",
      "Feature index 64 has a significant count of 46\n",
      "Feature index 68 has a significant count of 83\n",
      "Feature index 72 has a significant count of 50\n",
      "Feature index 85 has a significant count of 47\n",
      "Feature index 94 has a significant count of 57\n",
      "Results for Logistic Regression model trained on selected features with significance count of 40 or more:\n",
      "Accuracy: 0.9677\n",
      "Precision: 0.4737\n",
      "Recall: 0.2093\n",
      "F1 Score: 0.2903\n",
      "Feature index 2 has a significant count of 56\n",
      "Feature index 5 has a significant count of 79\n",
      "Feature index 15 has a significant count of 92\n",
      "Feature index 16 has a significant count of 60\n",
      "Feature index 17 has a significant count of 59\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 22 has a significant count of 60\n",
      "Feature index 32 has a significant count of 62\n",
      "Feature index 36 has a significant count of 91\n",
      "Feature index 37 has a significant count of 91\n",
      "Feature index 42 has a significant count of 99\n",
      "Feature index 44 has a significant count of 73\n",
      "Feature index 56 has a significant count of 98\n",
      "Feature index 59 has a significant count of 52\n",
      "Feature index 62 has a significant count of 91\n",
      "Feature index 68 has a significant count of 83\n",
      "Feature index 72 has a significant count of 50\n",
      "Feature index 94 has a significant count of 57\n",
      "Results for Logistic Regression model trained on selected features with significance count of 50 or more:\n",
      "Accuracy: 0.9663\n",
      "Precision: 0.4286\n",
      "Recall: 0.2093\n",
      "F1 Score: 0.2812\n",
      "Feature index 5 has a significant count of 79\n",
      "Feature index 15 has a significant count of 92\n",
      "Feature index 16 has a significant count of 60\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 22 has a significant count of 60\n",
      "Feature index 32 has a significant count of 62\n",
      "Feature index 36 has a significant count of 91\n",
      "Feature index 37 has a significant count of 91\n",
      "Feature index 42 has a significant count of 99\n",
      "Feature index 44 has a significant count of 73\n",
      "Feature index 56 has a significant count of 98\n",
      "Feature index 62 has a significant count of 91\n",
      "Feature index 68 has a significant count of 83\n",
      "Results for Logistic Regression model trained on selected features with significance count of 60 or more:\n",
      "Accuracy: 0.9633\n",
      "Precision: 0.3333\n",
      "Recall: 0.1628\n",
      "F1 Score: 0.2188\n",
      "Feature index 5 has a significant count of 79\n",
      "Feature index 15 has a significant count of 92\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 36 has a significant count of 91\n",
      "Feature index 37 has a significant count of 91\n",
      "Feature index 42 has a significant count of 99\n",
      "Feature index 44 has a significant count of 73\n",
      "Feature index 56 has a significant count of 98\n",
      "Feature index 62 has a significant count of 91\n",
      "Feature index 68 has a significant count of 83\n",
      "Results for Logistic Regression model trained on selected features with significance count of 70 or more:\n",
      "Accuracy: 0.9648\n",
      "Precision: 0.3684\n",
      "Recall: 0.1628\n",
      "F1 Score: 0.2258\n",
      "Feature index 15 has a significant count of 92\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 36 has a significant count of 91\n",
      "Feature index 37 has a significant count of 91\n",
      "Feature index 42 has a significant count of 99\n",
      "Feature index 56 has a significant count of 98\n",
      "Feature index 62 has a significant count of 91\n",
      "Feature index 68 has a significant count of 83\n",
      "Results for Logistic Regression model trained on selected features with significance count of 80 or more:\n",
      "Accuracy: 0.9670\n",
      "Precision: 0.4375\n",
      "Recall: 0.1628\n",
      "F1 Score: 0.2373\n",
      "Feature index 15 has a significant count of 92\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 36 has a significant count of 91\n",
      "Feature index 37 has a significant count of 91\n",
      "Feature index 42 has a significant count of 99\n",
      "Feature index 56 has a significant count of 98\n",
      "Feature index 62 has a significant count of 91\n",
      "Results for Logistic Regression model trained on selected features with significance count of 90 or more:\n",
      "Accuracy: 0.9663\n",
      "Precision: 0.4118\n",
      "Recall: 0.1628\n",
      "F1 Score: 0.2333\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 42 has a significant count of 99\n",
      "Feature index 56 has a significant count of 98\n",
      "Results for Logistic Regression model trained on selected features with significance count of 95 or more:\n",
      "Accuracy: 0.9670\n",
      "Precision: 0.4375\n",
      "Recall: 0.1628\n",
      "F1 Score: 0.2373\n",
      "Feature index 18 has a significant count of 100\n",
      "Feature index 42 has a significant count of 99\n",
      "Results for Logistic Regression model trained on selected features with significance count of 99 or more:\n",
      "Accuracy: 0.9677\n",
      "Precision: 0.4667\n",
      "Recall: 0.1628\n",
      "F1 Score: 0.2414\n"
     ]
    }
   ],
   "source": [
    "threshold = [0, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 99]\n",
    "print(final_features) # type: ignore\n",
    "\n",
    "for thresh in threshold:\n",
    "    new_feature_set = []\n",
    "    for feature_index, feature_data in final_features.items():\n",
    "        if feature_data['count'] >= thresh:\n",
    "            print(f\"Feature index {feature_index} has a significant count of {feature_data['count']}\")\n",
    "            new_feature_set.append(feature_index)\n",
    "\n",
    "    X_train_selected = X_train[:, new_feature_set]\n",
    "    X_test_selected = X_test[:, new_feature_set]\n",
    "\n",
    "    model_selected = LogisticRegression()\n",
    "    model_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_selected = model_selected.predict(X_test_selected)\n",
    "\n",
    "    # Calculate and print the evaluation metrics\n",
    "    accuracy_selected = accuracy_score(y_test, y_pred_selected)\n",
    "    precision_selected = precision_score(y_test, y_pred_selected)\n",
    "    recall_selected = recall_score(y_test, y_pred_selected)\n",
    "    f1_selected = f1_score(y_test, y_pred_selected)\n",
    "\n",
    "    print(f\"Results for Logistic Regression model trained on selected features with significance count of {thresh} or more:\")\n",
    "    print(f\"Accuracy: {accuracy_selected:.4f}\")\n",
    "    print(f\"Precision: {precision_selected:.4f}\")\n",
    "    print(f\"Recall: {recall_selected:.4f}\")\n",
    "    print(f\"F1 Score: {f1_selected:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
