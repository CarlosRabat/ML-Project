{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# Downlaod the Dataset \n",
    "taiwanese_bankruptcy_prediction = fetch_ucirepo(id=572) \n",
    "  \n",
    "# Get the features and target variables\n",
    "X = taiwanese_bankruptcy_prediction.data.features \n",
    "y = taiwanese_bankruptcy_prediction.data.targets \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 456494080.0000 - precision_5: 0.0438 - recall_5: 0.4420 - val_accuracy: 0.9707 - val_loss: 19350922.0000 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.9472 - loss: 19928768.0000 - precision_5: 0.0207 - recall_5: 0.0115 - val_accuracy: 0.9468 - val_loss: 11666447.0000 - val_precision_5: 0.0556 - val_recall_5: 0.0769\n",
      "Epoch 3/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.9334 - loss: 10989819.0000 - precision_5: 0.0460 - recall_5: 0.0445 - val_accuracy: 0.9643 - val_loss: 8206552.5000 - val_precision_5: 0.1176 - val_recall_5: 0.0769\n",
      "Epoch 4/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9427 - loss: 6479104.0000 - precision_5: 0.1344 - recall_5: 0.1153 - val_accuracy: 0.9560 - val_loss: 6624834.5000 - val_precision_5: 0.0417 - val_recall_5: 0.0385\n",
      "Epoch 5/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9405 - loss: 5180426.5000 - precision_5: 0.1254 - recall_5: 0.1241 - val_accuracy: 0.8781 - val_loss: 8895385.0000 - val_precision_5: 0.0180 - val_recall_5: 0.0769\n",
      "Epoch 6/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9410 - loss: 5517575.0000 - precision_5: 0.1210 - recall_5: 0.1505 - val_accuracy: 0.9102 - val_loss: 7171876.0000 - val_precision_5: 0.0135 - val_recall_5: 0.0385\n",
      "Epoch 7/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.9420 - loss: 4070485.2500 - precision_5: 0.1111 - recall_5: 0.0990 - val_accuracy: 0.9358 - val_loss: 6124027.5000 - val_precision_5: 0.0417 - val_recall_5: 0.0769\n",
      "Epoch 8/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.9443 - loss: 3398215.2500 - precision_5: 0.1440 - recall_5: 0.1369 - val_accuracy: 0.9478 - val_loss: 5611687.5000 - val_precision_5: 0.0811 - val_recall_5: 0.1154\n",
      "Epoch 9/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.9449 - loss: 3372473.2500 - precision_5: 0.1769 - recall_5: 0.1861 - val_accuracy: 0.9395 - val_loss: 5157659.5000 - val_precision_5: 0.0238 - val_recall_5: 0.0385\n",
      "Epoch 10/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9420 - loss: 3344404.0000 - precision_5: 0.1595 - recall_5: 0.1440 - val_accuracy: 0.9597 - val_loss: 4811228.0000 - val_precision_5: 0.0500 - val_recall_5: 0.0385\n",
      "Epoch 11/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.9440 - loss: 2864871.5000 - precision_5: 0.1636 - recall_5: 0.1665 - val_accuracy: 0.9212 - val_loss: 5564537.5000 - val_precision_5: 0.0455 - val_recall_5: 0.1154\n",
      "Epoch 12/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.9429 - loss: 3250511.5000 - precision_5: 0.1688 - recall_5: 0.1790 - val_accuracy: 0.8964 - val_loss: 5397930.5000 - val_precision_5: 0.0220 - val_recall_5: 0.0769\n",
      "Epoch 13/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.9362 - loss: 3216651.2500 - precision_5: 0.2241 - recall_5: 0.2813 - val_accuracy: 0.9441 - val_loss: 4511985.0000 - val_precision_5: 0.0270 - val_recall_5: 0.0385\n",
      "Epoch 14/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.9451 - loss: 2594104.5000 - precision_5: 0.2607 - recall_5: 0.2568 - val_accuracy: 0.9459 - val_loss: 4041427.2500 - val_precision_5: 0.0541 - val_recall_5: 0.0769\n",
      "Epoch 15/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.9495 - loss: 2329761.7500 - precision_5: 0.1469 - recall_5: 0.1328 - val_accuracy: 0.9496 - val_loss: 4497775.5000 - val_precision_5: 0.0606 - val_recall_5: 0.0769\n",
      "Epoch 16/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9471 - loss: 2303796.2500 - precision_5: 0.1895 - recall_5: 0.2003 - val_accuracy: 0.9514 - val_loss: 5136142.0000 - val_precision_5: 0.0345 - val_recall_5: 0.0385\n",
      "Epoch 17/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.9503 - loss: 2193245.2500 - precision_5: 0.1796 - recall_5: 0.1505 - val_accuracy: 0.8680 - val_loss: 5392051.5000 - val_precision_5: 0.0164 - val_recall_5: 0.0769\n",
      "Epoch 18/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9531 - loss: 2255237.2500 - precision_5: 0.3045 - recall_5: 0.3156 - val_accuracy: 0.9615 - val_loss: 3850976.5000 - val_precision_5: 0.1000 - val_recall_5: 0.0769\n",
      "Epoch 19/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9461 - loss: 1993411.8750 - precision_5: 0.2024 - recall_5: 0.1712 - val_accuracy: 0.9661 - val_loss: 3472729.7500 - val_precision_5: 0.0769 - val_recall_5: 0.0385\n",
      "Epoch 20/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9550 - loss: 1876660.3750 - precision_5: 0.2393 - recall_5: 0.1866 - val_accuracy: 0.9734 - val_loss: 3696077.0000 - val_precision_5: 0.2000 - val_recall_5: 0.0385\n",
      "Epoch 21/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9387 - loss: 2487103.5000 - precision_5: 0.2084 - recall_5: 0.2046 - val_accuracy: 0.9496 - val_loss: 3394134.0000 - val_precision_5: 0.0606 - val_recall_5: 0.0769\n",
      "Epoch 22/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9531 - loss: 1660263.5000 - precision_5: 0.2848 - recall_5: 0.2675 - val_accuracy: 0.9688 - val_loss: 3661016.2500 - val_precision_5: 0.1000 - val_recall_5: 0.0385\n",
      "Epoch 23/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9535 - loss: 1837071.7500 - precision_5: 0.2804 - recall_5: 0.2130 - val_accuracy: 0.9285 - val_loss: 3903561.5000 - val_precision_5: 0.0357 - val_recall_5: 0.0769\n",
      "Epoch 24/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9464 - loss: 1703384.2500 - precision_5: 0.2162 - recall_5: 0.1973 - val_accuracy: 0.9679 - val_loss: 3834642.5000 - val_precision_5: 0.0909 - val_recall_5: 0.0385\n",
      "Epoch 25/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9543 - loss: 1766459.6250 - precision_5: 0.2901 - recall_5: 0.2648 - val_accuracy: 0.9175 - val_loss: 4451231.5000 - val_precision_5: 0.0152 - val_recall_5: 0.0385\n",
      "Epoch 26/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9437 - loss: 1890971.7500 - precision_5: 0.1429 - recall_5: 0.1404 - val_accuracy: 0.9661 - val_loss: 3581295.2500 - val_precision_5: 0.0769 - val_recall_5: 0.0385\n",
      "Epoch 27/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9528 - loss: 1736162.1250 - precision_5: 0.3008 - recall_5: 0.3082 - val_accuracy: 0.9093 - val_loss: 3945724.0000 - val_precision_5: 0.0133 - val_recall_5: 0.0385\n",
      "Epoch 28/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9498 - loss: 1516613.2500 - precision_5: 0.3034 - recall_5: 0.3096 - val_accuracy: 0.9661 - val_loss: 3049021.2500 - val_precision_5: 0.1333 - val_recall_5: 0.0769\n",
      "Epoch 29/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9470 - loss: 1572193.5000 - precision_5: 0.2340 - recall_5: 0.1893 - val_accuracy: 0.9239 - val_loss: 3200702.0000 - val_precision_5: 0.0169 - val_recall_5: 0.0385\n",
      "Epoch 30/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9411 - loss: 1982677.1250 - precision_5: 0.2484 - recall_5: 0.2543 - val_accuracy: 0.8891 - val_loss: 3687396.0000 - val_precision_5: 0.0202 - val_recall_5: 0.0769\n",
      "Epoch 31/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9301 - loss: 2144974.5000 - precision_5: 0.1997 - recall_5: 0.2022 - val_accuracy: 0.8836 - val_loss: 4740558.5000 - val_precision_5: 0.0097 - val_recall_5: 0.0385\n",
      "Epoch 32/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9465 - loss: 2238243.7500 - precision_5: 0.2302 - recall_5: 0.2125 - val_accuracy: 0.9551 - val_loss: 2935623.2500 - val_precision_5: 0.0741 - val_recall_5: 0.0769\n",
      "Epoch 33/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9444 - loss: 1671715.3750 - precision_5: 0.2580 - recall_5: 0.2288 - val_accuracy: 0.9175 - val_loss: 3121138.7500 - val_precision_5: 0.0294 - val_recall_5: 0.0769\n",
      "Epoch 34/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9516 - loss: 1418568.3750 - precision_5: 0.2396 - recall_5: 0.2264 - val_accuracy: 0.9468 - val_loss: 2714003.7500 - val_precision_5: 0.0294 - val_recall_5: 0.0385\n",
      "Epoch 35/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9470 - loss: 1286555.7500 - precision_5: 0.2151 - recall_5: 0.1982 - val_accuracy: 0.9533 - val_loss: 2733937.0000 - val_precision_5: 0.0370 - val_recall_5: 0.0385\n",
      "Epoch 36/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9529 - loss: 1530844.7500 - precision_5: 0.3001 - recall_5: 0.2452 - val_accuracy: 0.9734 - val_loss: 2695459.7500 - val_precision_5: 0.2000 - val_recall_5: 0.0385\n",
      "Epoch 37/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9463 - loss: 1505278.0000 - precision_5: 0.1991 - recall_5: 0.1837 - val_accuracy: 0.9551 - val_loss: 2575056.7500 - val_precision_5: 0.0400 - val_recall_5: 0.0385\n",
      "Epoch 38/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.9491 - loss: 1119019.8750 - precision_5: 0.2438 - recall_5: 0.2116 - val_accuracy: 0.9652 - val_loss: 2364736.5000 - val_precision_5: 0.1250 - val_recall_5: 0.0769\n",
      "Epoch 39/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9583 - loss: 1030767.6875 - precision_5: 0.2993 - recall_5: 0.2702 - val_accuracy: 0.9441 - val_loss: 2514158.7500 - val_precision_5: 0.0732 - val_recall_5: 0.1154\n",
      "Epoch 40/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9503 - loss: 1152519.0000 - precision_5: 0.2446 - recall_5: 0.2365 - val_accuracy: 0.9551 - val_loss: 2865784.7500 - val_precision_5: 0.0400 - val_recall_5: 0.0385\n",
      "Epoch 41/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9572 - loss: 885531.8750 - precision_5: 0.2994 - recall_5: 0.2572 - val_accuracy: 0.9661 - val_loss: 2710207.5000 - val_precision_5: 0.0769 - val_recall_5: 0.0385\n",
      "Epoch 42/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9489 - loss: 1390643.0000 - precision_5: 0.2416 - recall_5: 0.2250 - val_accuracy: 0.8854 - val_loss: 3583511.5000 - val_precision_5: 0.0099 - val_recall_5: 0.0385\n",
      "Epoch 43/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9442 - loss: 1525303.1250 - precision_5: 0.2223 - recall_5: 0.2485 - val_accuracy: 0.9203 - val_loss: 2865707.5000 - val_precision_5: 0.0159 - val_recall_5: 0.0385\n",
      "Epoch 44/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9536 - loss: 1008666.6250 - precision_5: 0.3140 - recall_5: 0.3144 - val_accuracy: 0.9588 - val_loss: 2344968.5000 - val_precision_5: 0.0476 - val_recall_5: 0.0385\n",
      "Epoch 45/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9548 - loss: 1009527.5625 - precision_5: 0.3285 - recall_5: 0.2638 - val_accuracy: 0.9597 - val_loss: 2428866.2500 - val_precision_5: 0.0500 - val_recall_5: 0.0385\n",
      "Epoch 46/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9528 - loss: 1173593.0000 - precision_5: 0.2267 - recall_5: 0.1823 - val_accuracy: 0.9157 - val_loss: 2850651.0000 - val_precision_5: 0.0147 - val_recall_5: 0.0385\n",
      "Epoch 47/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9521 - loss: 862051.4375 - precision_5: 0.2381 - recall_5: 0.1975 - val_accuracy: 0.9468 - val_loss: 2513879.0000 - val_precision_5: 0.0294 - val_recall_5: 0.0385\n",
      "Epoch 48/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9476 - loss: 1030900.1250 - precision_5: 0.3260 - recall_5: 0.3266 - val_accuracy: 0.9633 - val_loss: 2508508.0000 - val_precision_5: 0.0625 - val_recall_5: 0.0385\n",
      "Epoch 49/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9499 - loss: 1018531.4375 - precision_5: 0.2390 - recall_5: 0.1995 - val_accuracy: 0.9615 - val_loss: 2169550.2500 - val_precision_5: 0.0556 - val_recall_5: 0.0385\n",
      "Epoch 50/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9471 - loss: 1156723.6250 - precision_5: 0.2606 - recall_5: 0.2231 - val_accuracy: 0.9670 - val_loss: 2218233.5000 - val_precision_5: 0.0833 - val_recall_5: 0.0385\n",
      "Epoch 51/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9615 - loss: 969577.6875 - precision_5: 0.3089 - recall_5: 0.2181 - val_accuracy: 0.9395 - val_loss: 2243598.7500 - val_precision_5: 0.0652 - val_recall_5: 0.1154\n",
      "Epoch 52/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.9475 - loss: 1045452.3750 - precision_5: 0.2260 - recall_5: 0.2180 - val_accuracy: 0.9432 - val_loss: 2661734.7500 - val_precision_5: 0.0909 - val_recall_5: 0.1538\n",
      "Epoch 53/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9503 - loss: 1379955.6250 - precision_5: 0.2609 - recall_5: 0.1925 - val_accuracy: 0.9624 - val_loss: 2300537.2500 - val_precision_5: 0.0588 - val_recall_5: 0.0385\n",
      "Epoch 54/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9435 - loss: 1112306.8750 - precision_5: 0.1927 - recall_5: 0.1631 - val_accuracy: 0.8387 - val_loss: 3127105.2500 - val_precision_5: 0.0253 - val_recall_5: 0.1538\n",
      "Epoch 55/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9489 - loss: 1169786.1250 - precision_5: 0.2442 - recall_5: 0.2646 - val_accuracy: 0.9340 - val_loss: 2257208.2500 - val_precision_5: 0.0400 - val_recall_5: 0.0769\n",
      "Epoch 56/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9567 - loss: 795392.4375 - precision_5: 0.3111 - recall_5: 0.3008 - val_accuracy: 0.9478 - val_loss: 2030110.8750 - val_precision_5: 0.0303 - val_recall_5: 0.0385\n",
      "Epoch 57/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9562 - loss: 640351.6875 - precision_5: 0.2939 - recall_5: 0.2816 - val_accuracy: 0.9056 - val_loss: 2640952.0000 - val_precision_5: 0.0471 - val_recall_5: 0.1538\n",
      "Epoch 58/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9435 - loss: 1258512.2500 - precision_5: 0.2554 - recall_5: 0.2247 - val_accuracy: 0.9588 - val_loss: 2003150.1250 - val_precision_5: 0.0476 - val_recall_5: 0.0385\n",
      "Epoch 59/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9535 - loss: 682435.1875 - precision_5: 0.3244 - recall_5: 0.2916 - val_accuracy: 0.9578 - val_loss: 2172028.2500 - val_precision_5: 0.0455 - val_recall_5: 0.0385\n",
      "Epoch 60/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9537 - loss: 865507.8750 - precision_5: 0.2637 - recall_5: 0.2470 - val_accuracy: 0.9698 - val_loss: 2277078.2500 - val_precision_5: 0.1111 - val_recall_5: 0.0385\n",
      "Epoch 61/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9463 - loss: 1153967.5000 - precision_5: 0.2014 - recall_5: 0.1722 - val_accuracy: 0.9093 - val_loss: 2375597.0000 - val_precision_5: 0.0260 - val_recall_5: 0.0769\n",
      "Epoch 62/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9520 - loss: 839569.0000 - precision_5: 0.2976 - recall_5: 0.3109 - val_accuracy: 0.9258 - val_loss: 2258554.7500 - val_precision_5: 0.0339 - val_recall_5: 0.0769\n",
      "Epoch 63/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9449 - loss: 858659.1250 - precision_5: 0.2181 - recall_5: 0.2202 - val_accuracy: 0.9368 - val_loss: 2234579.7500 - val_precision_5: 0.0222 - val_recall_5: 0.0385\n",
      "Epoch 64/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9499 - loss: 882393.3125 - precision_5: 0.2755 - recall_5: 0.2232 - val_accuracy: 0.9331 - val_loss: 1994641.1250 - val_precision_5: 0.0204 - val_recall_5: 0.0385\n",
      "Epoch 65/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9599 - loss: 464216.3750 - precision_5: 0.3502 - recall_5: 0.3572 - val_accuracy: 0.9624 - val_loss: 1922296.2500 - val_precision_5: 0.0588 - val_recall_5: 0.0385\n",
      "Epoch 66/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9572 - loss: 736097.2500 - precision_5: 0.3329 - recall_5: 0.2721 - val_accuracy: 0.9551 - val_loss: 1798858.8750 - val_precision_5: 0.0400 - val_recall_5: 0.0385\n",
      "Epoch 67/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9553 - loss: 941768.0000 - precision_5: 0.3262 - recall_5: 0.2912 - val_accuracy: 0.9670 - val_loss: 1662499.6250 - val_precision_5: 0.0833 - val_recall_5: 0.0385\n",
      "Epoch 68/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9529 - loss: 753446.0625 - precision_5: 0.2739 - recall_5: 0.2225 - val_accuracy: 0.9615 - val_loss: 1770914.0000 - val_precision_5: 0.0556 - val_recall_5: 0.0385\n",
      "Epoch 69/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9546 - loss: 634556.6875 - precision_5: 0.3502 - recall_5: 0.3015 - val_accuracy: 0.9523 - val_loss: 1572920.7500 - val_precision_5: 0.0357 - val_recall_5: 0.0385\n",
      "Epoch 70/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9584 - loss: 593098.4375 - precision_5: 0.3964 - recall_5: 0.3267 - val_accuracy: 0.9459 - val_loss: 2021064.5000 - val_precision_5: 0.0541 - val_recall_5: 0.0769\n",
      "Epoch 71/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9554 - loss: 712688.5625 - precision_5: 0.2547 - recall_5: 0.2687 - val_accuracy: 0.9496 - val_loss: 1696179.8750 - val_precision_5: 0.0606 - val_recall_5: 0.0769\n",
      "Epoch 72/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9504 - loss: 748756.5625 - precision_5: 0.2391 - recall_5: 0.1941 - val_accuracy: 0.9652 - val_loss: 1476233.7500 - val_precision_5: 0.1667 - val_recall_5: 0.1154\n",
      "Epoch 73/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9579 - loss: 551884.4375 - precision_5: 0.3638 - recall_5: 0.3915 - val_accuracy: 0.9065 - val_loss: 1584520.2500 - val_precision_5: 0.0366 - val_recall_5: 0.1154\n",
      "Epoch 74/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9489 - loss: 570587.9375 - precision_5: 0.2595 - recall_5: 0.2740 - val_accuracy: 0.9615 - val_loss: 1512845.7500 - val_precision_5: 0.0556 - val_recall_5: 0.0385\n",
      "Epoch 75/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9504 - loss: 736977.5000 - precision_5: 0.3355 - recall_5: 0.2847 - val_accuracy: 0.9615 - val_loss: 1536539.2500 - val_precision_5: 0.0556 - val_recall_5: 0.0385\n",
      "Epoch 76/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9622 - loss: 519968.7812 - precision_5: 0.4694 - recall_5: 0.3659 - val_accuracy: 0.8799 - val_loss: 1524114.7500 - val_precision_5: 0.0354 - val_recall_5: 0.1538\n",
      "Epoch 77/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9465 - loss: 635558.8750 - precision_5: 0.2405 - recall_5: 0.2444 - val_accuracy: 0.9606 - val_loss: 1220519.1250 - val_precision_5: 0.0952 - val_recall_5: 0.0769\n",
      "Epoch 78/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9533 - loss: 563838.4375 - precision_5: 0.2726 - recall_5: 0.2388 - val_accuracy: 0.9597 - val_loss: 1142663.2500 - val_precision_5: 0.1250 - val_recall_5: 0.1154\n",
      "Epoch 79/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9508 - loss: 486993.4688 - precision_5: 0.2822 - recall_5: 0.2516 - val_accuracy: 0.9533 - val_loss: 1198222.2500 - val_precision_5: 0.0370 - val_recall_5: 0.0385\n",
      "Epoch 80/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9513 - loss: 494195.5312 - precision_5: 0.2805 - recall_5: 0.2627 - val_accuracy: 0.9322 - val_loss: 1480500.3750 - val_precision_5: 0.0385 - val_recall_5: 0.0769\n",
      "Epoch 81/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9516 - loss: 655948.1250 - precision_5: 0.2158 - recall_5: 0.2178 - val_accuracy: 0.9597 - val_loss: 1513450.1250 - val_precision_5: 0.0500 - val_recall_5: 0.0385\n",
      "Epoch 82/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9567 - loss: 496368.9375 - precision_5: 0.2660 - recall_5: 0.2031 - val_accuracy: 0.9267 - val_loss: 1551294.3750 - val_precision_5: 0.0645 - val_recall_5: 0.1538\n",
      "Epoch 83/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.9504 - loss: 542925.4375 - precision_5: 0.2228 - recall_5: 0.2214 - val_accuracy: 0.9358 - val_loss: 1565476.6250 - val_precision_5: 0.0600 - val_recall_5: 0.1154\n",
      "Epoch 84/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9479 - loss: 544281.7500 - precision_5: 0.2791 - recall_5: 0.2722 - val_accuracy: 0.9597 - val_loss: 1557361.2500 - val_precision_5: 0.0909 - val_recall_5: 0.0769\n",
      "Epoch 85/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9564 - loss: 601820.8125 - precision_5: 0.2816 - recall_5: 0.2348 - val_accuracy: 0.9578 - val_loss: 1216206.6250 - val_precision_5: 0.0455 - val_recall_5: 0.0385\n",
      "Epoch 86/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9499 - loss: 446798.5938 - precision_5: 0.2977 - recall_5: 0.2655 - val_accuracy: 0.9322 - val_loss: 1206712.2500 - val_precision_5: 0.0200 - val_recall_5: 0.0385\n",
      "Epoch 87/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9488 - loss: 530600.5625 - precision_5: 0.2850 - recall_5: 0.2732 - val_accuracy: 0.9597 - val_loss: 1166701.1250 - val_precision_5: 0.0909 - val_recall_5: 0.0769\n",
      "Epoch 88/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.9485 - loss: 480623.0000 - precision_5: 0.2736 - recall_5: 0.2389 - val_accuracy: 0.9597 - val_loss: 1251375.8750 - val_precision_5: 0.0500 - val_recall_5: 0.0385\n",
      "Epoch 89/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9516 - loss: 645184.8750 - precision_5: 0.2647 - recall_5: 0.1972 - val_accuracy: 0.9698 - val_loss: 1235315.8750 - val_precision_5: 0.1111 - val_recall_5: 0.0385\n",
      "Epoch 90/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9586 - loss: 436312.6875 - precision_5: 0.2780 - recall_5: 0.2375 - val_accuracy: 0.9358 - val_loss: 1302499.2500 - val_precision_5: 0.0217 - val_recall_5: 0.0385\n",
      "Epoch 91/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9499 - loss: 493452.8125 - precision_5: 0.2801 - recall_5: 0.2801 - val_accuracy: 0.9569 - val_loss: 1209045.0000 - val_precision_5: 0.0435 - val_recall_5: 0.0385\n",
      "Epoch 92/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9494 - loss: 658869.4375 - precision_5: 0.2730 - recall_5: 0.2316 - val_accuracy: 0.9661 - val_loss: 1052601.7500 - val_precision_5: 0.0769 - val_recall_5: 0.0385\n",
      "Epoch 93/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9563 - loss: 339173.4062 - precision_5: 0.2594 - recall_5: 0.2291 - val_accuracy: 0.9386 - val_loss: 1209265.1250 - val_precision_5: 0.0233 - val_recall_5: 0.0385\n",
      "Epoch 94/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9531 - loss: 370066.0625 - precision_5: 0.2944 - recall_5: 0.3095 - val_accuracy: 0.9441 - val_loss: 950817.6250 - val_precision_5: 0.0732 - val_recall_5: 0.1154\n",
      "Epoch 95/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9529 - loss: 373828.7812 - precision_5: 0.2918 - recall_5: 0.2961 - val_accuracy: 0.9377 - val_loss: 1015704.2500 - val_precision_5: 0.0435 - val_recall_5: 0.0769\n",
      "Epoch 96/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9558 - loss: 315561.0938 - precision_5: 0.3609 - recall_5: 0.3153 - val_accuracy: 0.9120 - val_loss: 1051952.0000 - val_precision_5: 0.0395 - val_recall_5: 0.1154\n",
      "Epoch 97/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9492 - loss: 415975.5625 - precision_5: 0.2507 - recall_5: 0.2312 - val_accuracy: 0.9606 - val_loss: 1017591.0000 - val_precision_5: 0.0952 - val_recall_5: 0.0769\n",
      "Epoch 98/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9558 - loss: 333142.7188 - precision_5: 0.3175 - recall_5: 0.2910 - val_accuracy: 0.9633 - val_loss: 1013515.6875 - val_precision_5: 0.1111 - val_recall_5: 0.0769\n",
      "Epoch 99/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9522 - loss: 312811.5938 - precision_5: 0.3469 - recall_5: 0.3096 - val_accuracy: 0.9203 - val_loss: 924289.1250 - val_precision_5: 0.0822 - val_recall_5: 0.2308\n",
      "Epoch 100/100\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9482 - loss: 336687.3438 - precision_5: 0.2439 - recall_5: 0.2464 - val_accuracy: 0.9276 - val_loss: 881353.1875 - val_precision_5: 0.0794 - val_recall_5: 0.1923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x31bb5ba30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.metrics import Precision, Recall\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.9111 - loss: 4204955.5000 - precision_5: 0.0583 - recall_5: 0.1083\n",
      "Test loss: 3980375.75, Test accuracy: 0.9120234847068787, Precision: 0.0470588244497776, Recall: 0.09302325546741486\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
