{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# Downlaod the Dataset \n",
    "taiwanese_bankruptcy_prediction = fetch_ucirepo(id=572) \n",
    "  \n",
    "# Get the features and target variables\n",
    "X = taiwanese_bankruptcy_prediction.data.features \n",
    "y = taiwanese_bankruptcy_prediction.data.targets \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.6919 - loss: 276758528.0000 - precision_10: 0.0403 - recall_10: 0.3366 \n",
      "Epoch 2/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.9503 - loss: 13287351.0000 - precision_10: 0.1180 - recall_10: 0.0661     \n",
      "Epoch 3/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.9425 - loss: 6195688.5000 - precision_10: 0.0409 - recall_10: 0.0358      \n",
      "Epoch 4/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.9419 - loss: 5059177.0000 - precision_10: 0.0889 - recall_10: 0.0862      \n",
      "Epoch 5/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.9396 - loss: 4038111.0000 - precision_10: 0.1042 - recall_10: 0.0935     \n",
      "Epoch 6/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9490 - loss: 3526640.0000 - precision_10: 0.1028 - recall_10: 0.0790     \n",
      "Epoch 7/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9444 - loss: 3274077.7500 - precision_10: 0.0925 - recall_10: 0.0760     \n",
      "Epoch 8/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.9465 - loss: 2282679.0000 - precision_10: 0.1093 - recall_10: 0.1129\n",
      "Epoch 9/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9427 - loss: 2312605.5000 - precision_10: 0.1487 - recall_10: 0.1314\n",
      "Epoch 10/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9489 - loss: 2502736.2500 - precision_10: 0.1202 - recall_10: 0.1072      \n",
      "Epoch 11/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.9516 - loss: 2053937.2500 - precision_10: 0.1588 - recall_10: 0.1419      \n",
      "Epoch 12/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.9421 - loss: 2055946.8750 - precision_10: 0.1722 - recall_10: 0.1764    \n",
      "Epoch 13/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.9430 - loss: 1992092.1250 - precision_10: 0.0957 - recall_10: 0.1039      \n",
      "Epoch 14/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.9448 - loss: 1838049.0000 - precision_10: 0.2306 - recall_10: 0.2214      \n",
      "Epoch 15/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.9445 - loss: 1708410.2500 - precision_10: 0.1447 - recall_10: 0.1444      \n",
      "Epoch 16/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.9401 - loss: 1943870.0000 - precision_10: 0.1464 - recall_10: 0.1566      \n",
      "Epoch 17/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.9511 - loss: 1270577.7500 - precision_10: 0.1772 - recall_10: 0.1802    \n",
      "Epoch 18/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.9463 - loss: 1340601.5000 - precision_10: 0.2607 - recall_10: 0.2610\n",
      "Epoch 19/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.9546 - loss: 1094771.1250 - precision_10: 0.2126 - recall_10: 0.2249     \n",
      "Epoch 20/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.9395 - loss: 1451823.5000 - precision_10: 0.1616 - recall_10: 0.1867\n",
      "Epoch 21/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.9505 - loss: 1154872.2500 - precision_10: 0.2263 - recall_10: 0.2304    \n",
      "Epoch 22/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.9481 - loss: 1160515.3750 - precision_10: 0.2161 - recall_10: 0.2047      \n",
      "Epoch 23/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.9466 - loss: 1282414.5000 - precision_10: 0.1654 - recall_10: 0.1524      \n",
      "Epoch 24/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.9502 - loss: 1367474.2500 - precision_10: 0.1843 - recall_10: 0.1664      \n",
      "Epoch 25/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.9468 - loss: 1133009.1250 - precision_10: 0.2741 - recall_10: 0.2648\n",
      "Epoch 26/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9552 - loss: 742235.2500 - precision_10: 0.2686 - recall_10: 0.2435    \n",
      "Epoch 27/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9564 - loss: 1127331.5000 - precision_10: 0.2433 - recall_10: 0.2045    \n",
      "Epoch 28/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.9472 - loss: 1076066.1250 - precision_10: 0.2049 - recall_10: 0.1865      \n",
      "Epoch 29/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9487 - loss: 922488.5000 - precision_10: 0.2598 - recall_10: 0.2099\n",
      "Epoch 30/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.9533 - loss: 776718.5000 - precision_10: 0.2529 - recall_10: 0.2366    \n",
      "Epoch 31/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.9485 - loss: 945846.6875 - precision_10: 0.2389 - recall_10: 0.2453    \n",
      "Epoch 32/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.9497 - loss: 1052283.1250 - precision_10: 0.1611 - recall_10: 0.1645\n",
      "Epoch 33/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.9514 - loss: 731887.0625 - precision_10: 0.2031 - recall_10: 0.1769    \n",
      "Epoch 34/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.9526 - loss: 1008528.2500 - precision_10: 0.2631 - recall_10: 0.2244     \n",
      "Epoch 35/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.9602 - loss: 611848.1250 - precision_10: 0.3063 - recall_10: 0.2827 \n",
      "Epoch 36/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.9557 - loss: 824984.3750 - precision_10: 0.2823 - recall_10: 0.2615    \n",
      "Epoch 37/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.9509 - loss: 899300.2500 - precision_10: 0.2435 - recall_10: 0.2300    \n",
      "Epoch 38/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.9517 - loss: 705512.8750 - precision_10: 0.2946 - recall_10: 0.2709\n",
      "Epoch 39/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.9570 - loss: 578050.7500 - precision_10: 0.3225 - recall_10: 0.2878\n",
      "Epoch 40/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.9529 - loss: 616859.0000 - precision_10: 0.2650 - recall_10: 0.2741    \n",
      "Epoch 41/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.9563 - loss: 605973.1875 - precision_10: 0.2317 - recall_10: 0.2220     \n",
      "Epoch 42/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.9527 - loss: 725971.8125 - precision_10: 0.1767 - recall_10: 0.1551    \n",
      "Epoch 43/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.9554 - loss: 556374.3750 - precision_10: 0.2904 - recall_10: 0.2684\n",
      "Epoch 44/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.9494 - loss: 702876.5625 - precision_10: 0.2180 - recall_10: 0.2038     \n",
      "Epoch 45/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.9538 - loss: 647693.6875 - precision_10: 0.2296 - recall_10: 0.2074    \n",
      "Epoch 46/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.9459 - loss: 659406.7500 - precision_10: 0.2061 - recall_10: 0.1925     \n",
      "Epoch 47/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.9581 - loss: 471288.5312 - precision_10: 0.2305 - recall_10: 0.2009     \n",
      "Epoch 48/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.9461 - loss: 495722.9688 - precision_10: 0.2008 - recall_10: 0.2266\n",
      "Epoch 49/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.9552 - loss: 652291.4375 - precision_10: 0.2912 - recall_10: 0.2163\n",
      "Epoch 50/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.9570 - loss: 427354.5938 - precision_10: 0.1935 - recall_10: 0.1677    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x320ec3520>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.metrics import Precision, Recall\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.9443 - loss: 6398529.5000 - precision_10: 0.0578 - recall_10: 0.0509      \n",
      "Test loss: 5685806.5, Test accuracy: 0.9457477927207947, Precision: 0.0810810774564743, Recall: 0.06976744532585144\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
